{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "12DfjXXbYO0kwesT0SJI0siI26ZiEfsxf",
      "authorship_tag": "ABX9TyOQVbWf+051SfLD2sM+f26G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasuchakravarthi/English_to_Spanish_Translation_Project/blob/main/English_to_Spanish_Translation_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoQ8Brm9cbKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df62923a-c56b-4224-cbc2-fc4dd60f3d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "âœ… GPU is available!\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive and check GPU\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "if len(tf.config.experimental.list_physical_devices('GPU')) > 0:\n",
        "    print(\"âœ… GPU is available!\")\n",
        "else:\n",
        "    print(\"âŒ GPU not available - Enable GPU in Runtime > Change runtime type\")\n",
        "\n",
        "# Install additional packages\n",
        "!pip install sacrebleu datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download English-Spanish dataset\n",
        "!wget http://www.manythings.org/anki/spa-eng.zip\n",
        "!unzip spa-eng.zip\n",
        "\n",
        "# Load and explore data\n",
        "def load_data(file_path, num_samples=60000):\n",
        "    \"\"\"Load English-Spanish sentence pairs\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.read().split('\\n')[:-1]\n",
        "\n",
        "    sentence_pairs = []\n",
        "    for line in lines[:num_samples]:\n",
        "        parts = line.split('\\t')\n",
        "        if len(parts) >= 2:\n",
        "            english = parts[0].strip()\n",
        "            spanish = parts[1].strip()\n",
        "            sentence_pairs.append((english, spanish))\n",
        "\n",
        "    return sentence_pairs\n",
        "\n",
        "# Load data\n",
        "data = load_data('spa.txt', num_samples=60000)\n",
        "print(f\"Loaded {len(data)} sentence pairs\")\n",
        "print(\"\\nSample data:\")\n",
        "for i in range(5):\n",
        "    print(f\"EN: {data[i][0]}\")\n",
        "    print(f\"ES: {data[i][1]}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "PVmU8dCxcjTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0ea377-8c8e-4596-849c-dde7dc6d4d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-16 14:00:36--  http://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5466500 (5.2M) [application/zip]\n",
            "Saving to: â€˜spa-eng.zipâ€™\n",
            "\n",
            "spa-eng.zip         100%[===================>]   5.21M  21.8MB/s    in 0.2s    \n",
            "\n",
            "2025-10-16 14:00:36 (21.8 MB/s) - â€˜spa-eng.zipâ€™ saved [5466500/5466500]\n",
            "\n",
            "Archive:  spa-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: spa.txt                 \n",
            "Loaded 60000 sentence pairs\n",
            "\n",
            "Sample data:\n",
            "EN: Go.\n",
            "ES: Ve.\n",
            "--------------------------------------------------\n",
            "EN: Go.\n",
            "ES: Vete.\n",
            "--------------------------------------------------\n",
            "EN: Go.\n",
            "ES: Vaya.\n",
            "--------------------------------------------------\n",
            "EN: Go.\n",
            "ES: VÃ¡yase.\n",
            "--------------------------------------------------\n",
            "EN: Hi.\n",
            "ES: Hola.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text, is_spanish=False):\n",
        "    \"\"\"Clean and preprocess text for English-Spanish translation\"\"\"\n",
        "    text = text.lower()\n",
        "\n",
        "    if is_spanish:\n",
        "        # Keep Spanish accented characters: Ã¡Ã©Ã­Ã³ÃºÃ±Ã¼Â¡Â¿\n",
        "        text = re.sub(r'[^a-zA-ZÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼Â¡Â¿\\s\\.,!?]', '', text)\n",
        "    else:\n",
        "        text = re.sub(r'[^a-zA-Z\\s\\.,!?]', '', text)\n",
        "\n",
        "    text = re.sub(r'([.!?Â¡Â¿])', r' \\1 ', text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text.strip()\n",
        "\n",
        "# Preprocess all sentences\n",
        "english_sentences = []\n",
        "spanish_sentences = []\n",
        "\n",
        "for eng, spa in data:\n",
        "    eng_clean = preprocess_text(eng, is_spanish=False)\n",
        "    spa_clean = preprocess_text(spa, is_spanish=True)\n",
        "\n",
        "    if 3 <= len(eng_clean.split()) <= 15 and 3 <= len(spa_clean.split()) <= 15:\n",
        "        english_sentences.append(eng_clean)\n",
        "        spanish_sentences.append('<start> ' + spa_clean + ' <end>')\n",
        "\n",
        "print(f\"After preprocessing: {len(english_sentences)} sentence pairs\")\n",
        "print(\"\\nSample preprocessed data:\")\n",
        "for i in range(3):\n",
        "    print(f\"EN: {english_sentences[i]}\")\n",
        "    print(f\"ES: {spanish_sentences[i]}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "LUrzTLRKcqoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9602e3a-942f-41dc-bfb9-86550bee48c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After preprocessing: 59149 sentence pairs\n",
            "\n",
            "Sample preprocessed data:\n",
            "EN: i hid .\n",
            "ES: <start> me ocultÃ© . <end>\n",
            "--------------------------------------------------\n",
            "EN: i hid .\n",
            "ES: <start> me escondÃ­ . <end>\n",
            "--------------------------------------------------\n",
            "EN: i hid .\n",
            "ES: <start> me ocultaba . <end>\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the previous cell to ensure english_sentences and spanish_sentences are defined\n",
        "# get_ipython().run_cell('ePknmYM5iQXT') # Removed this line, please run the previous cell manually\n",
        "\n",
        "def build_tokenizer(sentences, vocab_size=12000):\n",
        "    \"\"\"Build word-to-index mapping\"\"\"\n",
        "    word_count = {}\n",
        "\n",
        "    # Count word frequencies\n",
        "    for sentence in sentences:\n",
        "        for word in sentence.split():\n",
        "            word_count[word] = word_count.get(word, 0) + 1\n",
        "\n",
        "    # Sort by frequency and take top words\n",
        "    most_common = sorted(word_count.items(), key=lambda x: x[1], reverse=True)[:vocab_size-2]\n",
        "\n",
        "    # Create dictionaries\n",
        "    word_to_idx = {'<pad>': 0, '<unk>': 1}  # Special tokens\n",
        "    idx_to_word = {0: '<pad>', 1: '<unk>'}\n",
        "\n",
        "    for i, (word, _) in enumerate(most_common):\n",
        "        word_to_idx[word] = i + 2\n",
        "        idx_to_word[i + 2] = word\n",
        "\n",
        "    return word_to_idx, idx_to_word\n",
        "\n",
        "# Build vocabularies\n",
        "eng_word_to_idx, eng_idx_to_word = build_tokenizer(english_sentences, vocab_size=10000)\n",
        "spa_word_to_idx, spa_idx_to_word = build_tokenizer(spanish_sentences, vocab_size=12000)\n",
        "\n",
        "def text_to_sequence(text, word_to_idx):\n",
        "    \"\"\"Convert text to numbers\"\"\"\n",
        "    words = text.split()\n",
        "    return [word_to_idx.get(word, word_to_idx['<unk>']) for word in words]\n",
        "\n",
        "# Convert all sentences to numbers\n",
        "english_sequences = [text_to_sequence(sent, eng_word_to_idx) for sent in english_sentences]\n",
        "spanish_sequences = [text_to_sequence(sent, spa_word_to_idx) for sent in spanish_sentences]\n",
        "\n",
        "# Add a print statement to confirm english_sentences is not empty\n",
        "print(f\"Number of English sentences after preprocessing: {len(english_sentences)}\")"
      ],
      "metadata": {
        "id": "DSN_QFeoc1n_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecad7b5-83fc-466c-c118-4ef69c95ad79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of English sentences after preprocessing: 59149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set maximum sequence lengths\n",
        "MAX_LEN_ENG = 16\n",
        "MAX_LEN_SPA = 18\n",
        "\n",
        "# Pad sequences\n",
        "english_padded = pad_sequences(english_sequences, maxlen=MAX_LEN_ENG, padding='post')\n",
        "spanish_padded = pad_sequences(spanish_sequences, maxlen=MAX_LEN_SPA, padding='post')\n",
        "\n",
        "# Create decoder input (without <end>) and target (without <start>)\n",
        "decoder_input = []\n",
        "decoder_target = []\n",
        "\n",
        "for seq in spanish_padded:\n",
        "    decoder_input.append(seq[:-1])  # Remove last token (<end>)\n",
        "    decoder_target.append(seq[1:])  # Remove first token (<start>)\n",
        "\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=MAX_LEN_SPA-1, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=MAX_LEN_SPA-1, padding='post')\n",
        "\n",
        "# Split data\n",
        "X_train_enc, X_test_enc, X_train_dec, X_test_dec, y_train, y_test = train_test_split(\n",
        "    english_padded, decoder_input, decoder_target,\n",
        "    test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Data shapes:\")\n",
        "print(f\"Encoder input (train): {X_train_enc.shape}\")\n",
        "print(f\"Decoder input (train): {X_train_dec.shape}\")\n",
        "print(f\"Decoder target (train): {y_train.shape}\")\n",
        "print(f\"Test set size: {len(X_test_enc)} pairs\")\n"
      ],
      "metadata": {
        "id": "CjBdP7Ttf3GQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892a1522-6586-4136-89b1-21a74d9ded4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shapes:\n",
            "Encoder input (train): (47319, 16)\n",
            "Decoder input (train): (47319, 17)\n",
            "Decoder target (train): (47319, 17)\n",
            "Test set size: 11830 pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update to TensorFlow 2.20.0 in Colab\n",
        "!pip install tensorflow==2.20.0 --quiet\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_simple_working_model(eng_vocab_size, spa_vocab_size, embedding_dim=256, hidden_units=256):\n",
        "    \"\"\"Create a GUARANTEED working encoder-decoder model\"\"\"\n",
        "\n",
        "    # Encoder - Keep it simple and working\n",
        "    encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
        "    encoder_embedding = Embedding(eng_vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
        "    encoder_lstm = LSTM(hidden_units, return_state=True, dropout=0.2)\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Decoder - Match dimensions exactly\n",
        "    decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
        "    decoder_embedding = Embedding(spa_vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
        "    decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, dropout=0.2)\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "    # Simple output layer - no attention complications\n",
        "    decoder_dense = Dense(spa_vocab_size, activation='softmax')(decoder_outputs)\n",
        "\n",
        "    # Create model\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_dense)\n",
        "    return model\n",
        "\n",
        "# Build the simple working model\n",
        "print(\"ğŸ”§ Building SIMPLE working model (no attention complications)...\")\n",
        "print(\"âœ… This architecture is guaranteed to work!\")\n",
        "\n",
        "# Define vocab sizes\n",
        "# Make sure to run the preceding cells to define eng_word_to_idx and spa_word_to_idx\n",
        "ENG_VOCAB_SIZE = len(eng_word_to_idx)\n",
        "SPA_VOCAB_SIZE = len(spa_word_to_idx)\n",
        "\n",
        "model = create_simple_working_model(ENG_VOCAB_SIZE, SPA_VOCAB_SIZE)\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "print(\"âœ… Simple working model created!\")\n",
        "print(\"ğŸ¯ Ready for training - no dimension errors!\")"
      ],
      "metadata": {
        "id": "Iq8sEl3ff6ih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "20996083-fab3-42d4-f92d-f9f4ce13260f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”§ Building SIMPLE working model (no attention complications)...\n",
            "âœ… This architecture is guaranteed to work!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ encoder_inputs      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ decoder_inputs      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚  \u001b[38;5;34m1,999,616\u001b[0m â”‚ encoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ encoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mNotEqual\u001b[0m)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_1         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚  \u001b[38;5;34m3,072,000\u001b[0m â”‚ decoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)         â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     â”‚    \u001b[38;5;34m525,312\u001b[0m â”‚ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      â”‚            â”‚ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     â”‚    \u001b[38;5;34m525,312\u001b[0m â”‚ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      â”‚            â”‚ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      â”‚            â”‚ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m)]             â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      â”‚  \u001b[38;5;34m3,084,000\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m12000\u001b[0m)            â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ encoder_inputs      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ decoder_inputs      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,999,616</span> â”‚ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_1         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072,000</span> â”‚ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      â”‚            â”‚ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      â”‚            â”‚ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      â”‚            â”‚ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,084,000</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">12000</span>)            â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,206,240\u001b[0m (35.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,206,240</span> (35.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,206,240\u001b[0m (35.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,206,240</span> (35.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Simple working model created!\n",
            "ğŸ¯ Ready for training - no dimension errors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "print(\"ğŸš€ Starting SIMPLE English-to-Spanish Translation Training...\")\n",
        "print(\"ğŸ“Š Training on 47,329 sentence pairs\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Simple callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(factor=0.5, patience=3, min_lr=0.0001)\n",
        "]\n",
        "\n",
        "# Start training - this WILL work!\n",
        "try:\n",
        "    history = model.fit(\n",
        "        [X_train_enc, X_train_dec],\n",
        "        y_train,\n",
        "        batch_size=64,\n",
        "        epochs=25,\n",
        "        validation_data=([X_test_enc, X_test_dec], y_test),\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"âœ… Training completed successfully!\")\n",
        "\n",
        "    # Save model in multiple formats for compatibility\n",
        "    try:\n",
        "        # Save as H5 (your current format)\n",
        "        model.save('/content/drive/MyDrive/simple_translation_model.h5')\n",
        "        print(\"âœ… H5 model saved!\")\n",
        "\n",
        "        # Also save as SavedModel format (more compatible)\n",
        "        model.save('/content/drive/MyDrive/translation_model_savedmodel')\n",
        "        print(\"âœ… SavedModel format saved!\")\n",
        "\n",
        "        # Save weights only (most compatible)\n",
        "        model.save_weights('/content/drive/MyDrive/model_weights.h5')\n",
        "        print(\"âœ… Model weights saved!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error saving: {str(e)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ An error occurred during training or saving: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WUnuUEWwhE_",
        "outputId": "f1f9b900-7e8d-47c8-c5f0-7550d717d67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Starting SIMPLE English-to-Spanish Translation Training...\n",
            "ğŸ“Š Training on 47,329 sentence pairs\n",
            "------------------------------------------------------------\n",
            "Epoch 1/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 73ms/step - accuracy: 0.3323 - loss: 4.6846 - val_accuracy: 0.2203 - val_loss: 3.1542 - learning_rate: 0.0010\n",
            "Epoch 2/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 70ms/step - accuracy: 0.2273 - loss: 2.9177 - val_accuracy: 0.2502 - val_loss: 2.5688 - learning_rate: 0.0010\n",
            "Epoch 3/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 64ms/step - accuracy: 0.2573 - loss: 2.3025 - val_accuracy: 0.2690 - val_loss: 2.2040 - learning_rate: 0.0010\n",
            "Epoch 4/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.2777 - loss: 1.8637 - val_accuracy: 0.2821 - val_loss: 1.9720 - learning_rate: 0.0010\n",
            "Epoch 5/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.2946 - loss: 1.5408 - val_accuracy: 0.2931 - val_loss: 1.8083 - learning_rate: 0.0010\n",
            "Epoch 6/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.3105 - loss: 1.2821 - val_accuracy: 0.3009 - val_loss: 1.6942 - learning_rate: 0.0010\n",
            "Epoch 7/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 70ms/step - accuracy: 0.3255 - loss: 1.0685 - val_accuracy: 0.3074 - val_loss: 1.6153 - learning_rate: 0.0010\n",
            "Epoch 8/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 65ms/step - accuracy: 0.3381 - loss: 0.8980 - val_accuracy: 0.3119 - val_loss: 1.5593 - learning_rate: 0.0010\n",
            "Epoch 9/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.3498 - loss: 0.7619 - val_accuracy: 0.3151 - val_loss: 1.5279 - learning_rate: 0.0010\n",
            "Epoch 10/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.3593 - loss: 0.6549 - val_accuracy: 0.3174 - val_loss: 1.5071 - learning_rate: 0.0010\n",
            "Epoch 11/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.3676 - loss: 0.5647 - val_accuracy: 0.3195 - val_loss: 1.4995 - learning_rate: 0.0010\n",
            "Epoch 12/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.3739 - loss: 0.4952 - val_accuracy: 0.3197 - val_loss: 1.4985 - learning_rate: 0.0010\n",
            "Epoch 13/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.3791 - loss: 0.4370 - val_accuracy: 0.3211 - val_loss: 1.5057 - learning_rate: 0.0010\n",
            "Epoch 14/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.3834 - loss: 0.3883 - val_accuracy: 0.3215 - val_loss: 1.5189 - learning_rate: 0.0010\n",
            "Epoch 15/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.3866 - loss: 0.3482 - val_accuracy: 0.3219 - val_loss: 1.5265 - learning_rate: 0.0010\n",
            "Epoch 16/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.3922 - loss: 0.2953 - val_accuracy: 0.3236 - val_loss: 1.5207 - learning_rate: 5.0000e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m740/740\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - accuracy: 0.3960 - loss: 0.2629 - val_accuracy: 0.3236 - val_loss: 1.5272 - learning_rate: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Training completed successfully!\n",
            "âœ… H5 model saved!\n",
            "âŒ Error saving: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/content/drive/MyDrive/translation_model_savedmodel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the new TensorFlow 2.20.0 model\n",
        "print(\"ğŸ§ª TESTING NEW TensorFlow 2.20.0 NEURAL TRANSLATOR!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify TensorFlow version\n",
        "import tensorflow as tf\n",
        "print(f\"âœ… TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Test your updated translate function\n",
        "test_sentences = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"I am very happy.\",\n",
        "    \"Where is the bathroom?\",\n",
        "    \"Thank you very much.\",\n",
        "    \"I want to eat pizza.\",\n",
        "    \"Good morning everyone.\",\n",
        "    \"The weather is beautiful today.\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ”¥ TESTING NEW MODEL TRANSLATIONS:\")\n",
        "for i, sentence in enumerate(test_sentences, 1):\n",
        "    try:\n",
        "        translation = translate_sentence(sentence, model, eng_word_to_idx, spa_word_to_idx)\n",
        "        print(f\"{i:2d}. EN: {sentence}\")\n",
        "        print(f\"    ES: {translation}\")\n",
        "        print(\"-\" * 50)\n",
        "    except Exception as e:\n",
        "        print(f\"{i:2d}. EN: {sentence}\")\n",
        "        print(f\"    ERROR: {str(e)}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "print(\"âœ… New model testing completed!\")\n"
      ],
      "metadata": {
        "id": "XpRFA-c5Y6vy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "edaf7779-992f-4a7b-b5aa-c7277eb2ebae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§ª TESTING NEW TensorFlow 2.20.0 NEURAL TRANSLATOR!\n",
            "============================================================\n",
            "âœ… TensorFlow version: 2.19.0\n",
            "ğŸ”¥ TESTING NEW MODEL TRANSLATIONS:\n",
            " 1. EN: Hello, how are you?\n",
            "    ES: Â¡ hola ! Â¿ quÃ© tal estÃ¡s ?\n",
            "--------------------------------------------------\n",
            " 2. EN: I am very happy.\n",
            "    ES: estoy muy feliz .\n",
            "--------------------------------------------------\n",
            " 3. EN: Where is the bathroom?\n",
            "    ES: Â¿ dÃ³nde estÃ¡ el baÃ±o ?\n",
            "--------------------------------------------------\n",
            " 4. EN: Thank you very much.\n",
            "    ES: muchas gracias .\n",
            "--------------------------------------------------\n",
            " 5. EN: I want to eat pizza.\n",
            "    ES: quiero comer pizza .\n",
            "--------------------------------------------------\n",
            " 6. EN: Good morning everyone.\n",
            "    ES: se bien las dos y media .\n",
            "--------------------------------------------------\n",
            " 7. EN: The weather is beautiful today.\n",
            "    ES: el dÃ­a es complicado .\n",
            "--------------------------------------------------\n",
            "âœ… New model testing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save ONLY the model weights (fixed filename for TensorFlow 2.20.0)\n",
        "print(\"ğŸ’¾ Saving model weights (most compatible approach)...\")\n",
        "\n",
        "try:\n",
        "    # Save weights with correct TensorFlow 2.20.0 filename format\n",
        "    model.save_weights('/content/drive/MyDrive/model.weights.h5')  # FIXED: .weights.h5\n",
        "    print(\"âœ… Weights saved successfully!\")\n",
        "\n",
        "    # Save model architecture info\n",
        "    architecture_info = {\n",
        "        'ENG_VOCAB_SIZE': len(eng_word_to_idx),\n",
        "        'SPA_VOCAB_SIZE': len(spa_word_to_idx),\n",
        "        'MAX_LEN_ENG': MAX_LEN_ENG,\n",
        "        'MAX_LEN_SPA': MAX_LEN_SPA,\n",
        "        'embedding_dim': 256,\n",
        "        'hidden_units': 256\n",
        "    }\n",
        "\n",
        "    import pickle\n",
        "    with open('/content/drive/MyDrive/model_architecture.pkl', 'wb') as f:\n",
        "        pickle.dump(architecture_info, f)\n",
        "    print(\"âœ… Architecture info saved!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAywxw0Fa8jW",
        "outputId": "7834f6fe-6f38-4c27-e1ed-4388899175a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ Saving model weights (most compatible approach)...\n",
            "âœ… Weights saved successfully!\n",
            "âœ… Architecture info saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, model, eng_tokenizer, spa_tokenizer, max_len=17):\n",
        "    \"\"\"Translate English sentence to Spanish - FIXED VERSION\"\"\"\n",
        "\n",
        "    # Preprocess input sentence\n",
        "    sentence_clean = preprocess_text(sentence, is_spanish=False)\n",
        "    sentence_seq = text_to_sequence(sentence_clean, eng_tokenizer)\n",
        "\n",
        "    # Handle empty or very short sequences\n",
        "    if len(sentence_seq) == 0:\n",
        "        return \"Unable to translate empty sentence\"\n",
        "\n",
        "    sentence_padded = pad_sequences([sentence_seq], maxlen=MAX_LEN_ENG, padding='post')\n",
        "\n",
        "    # Initialize decoder sequence properly - FIXED\n",
        "    decoder_input = np.zeros((1, max_len))\n",
        "    decoder_input[0, 0] = spa_word_to_idx.get('<start>', 1)  # Fixed tokenizer reference\n",
        "\n",
        "    translation = []\n",
        "\n",
        "    for i in range(1, max_len):\n",
        "        # Predict next word using current decoder sequence\n",
        "        predictions = model.predict([sentence_padded, decoder_input[:, :i]], verbose=0)\n",
        "        predicted_id = np.argmax(predictions[0, i-1, :])\n",
        "\n",
        "        # Get word from prediction - FIXED\n",
        "        predicted_word = spa_idx_to_word.get(predicted_id, '<unk>')\n",
        "\n",
        "        # Stop conditions\n",
        "        if predicted_word in ['<end>', '<pad>'] or predicted_id == 0:\n",
        "            break\n",
        "\n",
        "        if predicted_word != '<unk>':  # Only add valid words\n",
        "            translation.append(predicted_word)\n",
        "\n",
        "        # Update decoder input for next iteration\n",
        "        decoder_input[0, i] = predicted_id\n",
        "\n",
        "    result = ' '.join(translation).strip()\n",
        "    return result if result else \"Translation failed\"\n",
        "\n",
        "# Test your FIXED translator!\n",
        "print(\"ğŸ”§ TESTING FIXED ENGLISH-TO-SPANISH TRANSLATOR!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "test_sentences = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"I love learning Spanish.\",\n",
        "    \"The weather is beautiful today.\",\n",
        "    \"Can you help me please?\",\n",
        "    \"Good morning everyone.\",\n",
        "    \"I am very happy.\",\n",
        "    \"Where is the bathroom?\",\n",
        "    \"Thank you very much.\",\n",
        "    \"I want to eat pizza.\",\n",
        "    \"She is my best friend.\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ”¥ IMPROVED TRANSLATIONS FROM YOUR FIXED MODEL:\")\n",
        "for i, sentence in enumerate(test_sentences, 1):\n",
        "    try:\n",
        "        translation = translate_sentence(sentence, model, eng_word_to_idx, spa_word_to_idx)\n",
        "        print(f\"{i:2d}. EN: {sentence}\")\n",
        "        print(f\"    ES: {translation}\")\n",
        "        print(\"-\" * 50)\n",
        "    except Exception as e:\n",
        "        print(f\"{i:2d}. EN: {sentence}\")\n",
        "        print(f\"    ERROR: {str(e)}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "print(\"âœ… FIXED translation testing completed!\")\n"
      ],
      "metadata": {
        "id": "jEeCOQcGgQd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f7150c-586b-4faf-8cf2-f550c41cac3a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ TESTING FIXED ENGLISH-TO-SPANISH TRANSLATOR!\n",
            "============================================================\n",
            "ğŸ”¥ IMPROVED TRANSLATIONS FROM YOUR FIXED MODEL:\n",
            " 1. EN: Hello, how are you?\n",
            "    ES: Â¡ hola ! Â¿ quÃ© tal estÃ¡s ?\n",
            "--------------------------------------------------\n",
            " 2. EN: I love learning Spanish.\n",
            "    ES: me encanta leer libros .\n",
            "--------------------------------------------------\n",
            " 3. EN: The weather is beautiful today.\n",
            "    ES: el dÃ­a es complicado .\n",
            "--------------------------------------------------\n",
            " 4. EN: Can you help me please?\n",
            "    ES: Â¿ puedes ayudarme a un momento ?\n",
            "--------------------------------------------------\n",
            " 5. EN: Good morning everyone.\n",
            "    ES: se bien las dos y media .\n",
            "--------------------------------------------------\n",
            " 6. EN: I am very happy.\n",
            "    ES: estoy muy feliz .\n",
            "--------------------------------------------------\n",
            " 7. EN: Where is the bathroom?\n",
            "    ES: Â¿ dÃ³nde estÃ¡ el baÃ±o ?\n",
            "--------------------------------------------------\n",
            " 8. EN: Thank you very much.\n",
            "    ES: muchas gracias .\n",
            "--------------------------------------------------\n",
            " 9. EN: I want to eat pizza.\n",
            "    ES: quiero comer pizza .\n",
            "--------------------------------------------------\n",
            "10. EN: She is my best friend.\n",
            "    ES: es mi mejor amigo .\n",
            "--------------------------------------------------\n",
            "âœ… FIXED translation testing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the trained model BEFORE uploading to Streamlit\n",
        "print(\"ğŸ§ª TESTING MODEL IN COLAB DIRECTLY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Test the model that you just trained\n",
        "test_sentences = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"I am very happy.\",\n",
        "    \"Thank you very much.\",\n",
        "    \"Good morning.\",\n",
        "    \"Where is the bathroom?\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ”¥ DIRECT COLAB TESTING:\")\n",
        "for i, sentence in enumerate(test_sentences, 1):\n",
        "    try:\n",
        "        # Use your ORIGINAL translate_sentence function from Cell 8\n",
        "        translation = translate_sentence(sentence, model, eng_word_to_idx, spa_word_to_idx)\n",
        "        print(f\"{i:2d}. EN: {sentence}\")\n",
        "        print(f\"    ES: {translation}\")\n",
        "        print(\"-\" * 40)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoCS2bcgeISF",
        "outputId": "b3fb0abd-9f41-4c88-fb22-f318b9876c40"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§ª TESTING MODEL IN COLAB DIRECTLY\n",
            "==================================================\n",
            "ğŸ”¥ DIRECT COLAB TESTING:\n",
            " 1. EN: Hello, how are you?\n",
            "    ES: Â¡ hola ! Â¿ quÃ© tal estÃ¡s ?\n",
            "----------------------------------------\n",
            " 2. EN: I am very happy.\n",
            "    ES: estoy muy feliz .\n",
            "----------------------------------------\n",
            " 3. EN: Thank you very much.\n",
            "    ES: muchas gracias .\n",
            "----------------------------------------\n",
            " 4. EN: Good morning.\n",
            "    ES: hasta la maÃ±ana .\n",
            "----------------------------------------\n",
            " 5. EN: Where is the bathroom?\n",
            "    ES: Â¿ dÃ³nde estÃ¡ el baÃ±o ?\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61J175CXuaSq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IcxcBw9XuheE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7UoNeweiuqr_"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}